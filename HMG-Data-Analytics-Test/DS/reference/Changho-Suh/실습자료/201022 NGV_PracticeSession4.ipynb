{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist data 가져오기\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(Xm_train, ym_train), (Xm_test, ym_test) = mnist.load_data()\n",
    "Xm_train, Xm_test = Xm_train / 255.0, Xm_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de804e23c8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist DNN - Sequential 만들기\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "model_DNN = Sequential()\n",
    "model_DNN.add(Flatten(input_shape=(28,28)))    #input\n",
    "model_DNN.add(Dense(128, activation='relu'))   #1\n",
    "model_DNN.add(Dense(10, activation='softmax')) #output\n",
    "\n",
    "model_DNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model_DNN.fit(X_train, y_train, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 915us/step - loss: 0.0838 - acc: 0.9781\n",
      "97.81%\n",
      "\n",
      "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DE8590D4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[2.1562900e-10 1.4293804e-10 3.8588951e-07 1.5534673e-06 1.6031752e-12\n",
      "  2.0845813e-10 6.5519289e-17 9.9999595e-01 1.3791909e-07 1.9725489e-06]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1de8575ad88>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x1de857ae688>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de857ae9c8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de857ae848>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_DNN 확인\n",
    "\n",
    "model=model_DNN\n",
    "\n",
    "(test_loss, test_acc) = model.evaluate(X_test,y_test)\n",
    "print('{:.2f}%\\n'.format(100*test_acc))\n",
    "\n",
    "print(model.predict(X_test[0].reshape(1,28,28)))\n",
    "\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 샘플 확인\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i=13\n",
    "X=Xm_train[i]\n",
    "y=ym_train[i]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(X, cmap='gray')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de8babcf08>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist CNN 만들기 (filter개수, filter크기, padding, stride)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D\n",
    "\n",
    "model_lenet = Sequential()\n",
    "\n",
    "#1st layer : [Conv]+[ReLU]+[Pool]\n",
    "model_lenet.add(Conv2D(input_shape=(28,28,1),   # 28*28(사이즈)*1(채널-흑백:1,RGB:3)\n",
    "                      kernel_size=(3,3),        # filter 크기\n",
    "                      filters=32,\n",
    "                      strides=(1,1),\n",
    "                      padding='same',\n",
    "                      activation='relu'))\n",
    "model_lenet.add(MaxPool2D(pool_size=(2,2),\n",
    "                         strides=(2,2),\n",
    "                         padding='valid'))\n",
    "\n",
    "#2nd layer : [Conv]+[ReLU]+[Pool]\n",
    "model_lenet.add(Conv2D(kernel_size=(5,5),        # filter 크기\n",
    "                      filters=48,\n",
    "                      strides=(1,1),\n",
    "                      padding='same',\n",
    "                      activation='relu'))\n",
    "model_lenet.add(MaxPool2D(pool_size=(2,2),\n",
    "                         strides=(2,2),\n",
    "                         padding='valid'))\n",
    "\n",
    "#3rd layer\n",
    "model_lenet.add(Flatten())                         # input_shape 은 처음에만 \n",
    "model_lenet.add(Dense(256, activation='relu'))\n",
    "\n",
    "#4th layer\n",
    "model_lenet.add(Dense(128, activation='relu'))\n",
    "\n",
    "#output\n",
    "model_lenet.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_lenet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model_lenet.fit(X_train.reshape(-1,28,28,1), y_train, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 30720000 into shape (28,28,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-040db096aea7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_lenet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{:.2f}%\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 30720000 into shape (28,28,1)"
     ]
    }
   ],
   "source": [
    "# model_lenet 확인\n",
    "\n",
    "model=model_lenet\n",
    "\n",
    "(test_loss, test_acc) = model.evaluate(X_test.reshape(-1,28,28,1),y_test)\n",
    "print('{:.2f}%\\n'.format(100*test_acc))\n",
    "\n",
    "print(model.predict(X_test[0].reshape(1,28,28,1)))\n",
    "\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 733s 4us/step\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10 data 가져오기\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de808abec8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR10 alexnet 만들기\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D\n",
    "\n",
    "model_alex = Sequential()\n",
    "\n",
    "#1st layer : [Conv]+[ReLU]+[Pool]\n",
    "model_alex.add(Conv2D(input_shape=(32,32,3),   # 모르겠으면 X_train.shape 해서 그대로\n",
    "                      kernel_size=(3,3),        # filter 크기\n",
    "                      filters=48,\n",
    "                      strides=(1,1),\n",
    "                      padding='same',\n",
    "                      activation='relu'))\n",
    "model_alex.add(MaxPool2D(pool_size=(2,2),\n",
    "                         strides=(2,2),\n",
    "                         padding='valid'))\n",
    "\n",
    "#2nd layer : [Conv]+[ReLU]+[Pool]\n",
    "model_alex.add(Conv2D(kernel_size=(3,3),\n",
    "                      filters=96,\n",
    "                      strides=(1,1),\n",
    "                      padding='same',\n",
    "                      activation='relu'))\n",
    "model_alex.add(MaxPool2D(pool_size=(2,2),\n",
    "                         strides=(2,2),\n",
    "                         padding='valid'))\n",
    "\n",
    "#3rd layer\n",
    "model_alex.add(Conv2D(kernel_size=(3,3),\n",
    "                      filters=192,\n",
    "                      strides=(1,1),\n",
    "                      padding='same',\n",
    "                      activation='relu'))\n",
    "\n",
    "#4th layer\n",
    "model_alex.add(Conv2D(kernel_size=(3,3),\n",
    "                      filters=192,\n",
    "                      strides=(1,1),\n",
    "                      padding='same',\n",
    "                      activation='relu'))\n",
    "\n",
    "#5th layer : [Conv]+[ReLU]+[Pool]\n",
    "model_alex.add(Conv2D(kernel_size=(3,3),\n",
    "                      filters=256,\n",
    "                      strides=(1,1),\n",
    "                      padding='same',\n",
    "                      activation='relu'))\n",
    "model_alex.add(MaxPool2D(pool_size=(2,2),\n",
    "                         strides=(2,2),\n",
    "                         padding='valid'))\n",
    "\n",
    "#6th layer\n",
    "model_alex.add(Flatten())                         # input_shape 은 처음에만 \n",
    "model_alex.add(Dense(512, activation='relu'))\n",
    "\n",
    "#7th layer\n",
    "model_alex.add(Dense(256, activation='relu'))\n",
    "\n",
    "#output\n",
    "model_alex.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_alex.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model_alex.fit(X_train.reshape(-1,32,32,3), y_train, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 20ms/step - loss: 0.8142 - acc: 0.7254\n",
      "72.54%\n",
      "\n",
      "[[0.00171434 0.00266545 0.00498872 0.512295   0.00139883 0.45029518\n",
      "  0.00499675 0.00557925 0.00668131 0.00938508]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x1de80844948>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1de80854388>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1de8084a588>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1de8084a1c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1de8085cfc8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1de8085c448>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1de80864a08>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1de8086d9c8>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x1de80875848>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de808785c8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de8087fc88>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de80878608>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_alex 확인\n",
    "\n",
    "model=model_alex\n",
    "\n",
    "(test_loss, test_acc) = model.evaluate(X_test.reshape(-1,32,32,3),y_test)\n",
    "print('{:.2f}%\\n'.format(100*test_acc))\n",
    "\n",
    "print(model.predict(X_test[0].reshape(1,32,32,3)))\n",
    "\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de85ae4048>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist DNN -model 만들기\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input\n",
    "\n",
    "inputs = Input(shape=(28,28))\n",
    "flatten = Flatten()(inputs)\n",
    "hidden1 = Dense(128, activation='relu')(flatten)   #1\n",
    "hidden2 = Dense(256, activation='relu')(hidden1)   #2\n",
    "hidden3 = Dense(128, activation='relu')(hidden2)   #3\n",
    "outputs = Dense(10, activation='softmax')(hidden3) #output\n",
    "model_NN = Model(inputs=inputs,outputs=outputs)\n",
    "\n",
    "model_NN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model_NN.fit(Xm_train, ym_train, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 676us/step - loss: 0.0814 - acc: 0.9799\n",
      "97.99%\n",
      "\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DE85B2CCA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[6.19717439e-13 6.02397021e-09 1.48855435e-08 2.13779480e-11\n",
      "  8.33181790e-09 4.98888582e-13 3.23157959e-19 9.99999523e-01\n",
      "  2.87261603e-11 4.71141163e-07]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1de85aaf1c8>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x1de85aaf408>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de85aaf888>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de85aafb48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de85ab1648>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1de85ab2c48>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_NN 확인\n",
    "\n",
    "model=model_NN\n",
    "\n",
    "(test_loss, test_acc) = model.evaluate(Xm_test,ym_test)\n",
    "print('{:.2f}%\\n'.format(100*test_acc))\n",
    "\n",
    "print(model.predict(Xm_test[0].reshape(1,28,28)))\n",
    "\n",
    "model.layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
